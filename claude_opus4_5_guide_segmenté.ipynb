{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annakalinina18/star-fle/blob/main/claude_opus4_5_guide_segment%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mxUtaWPljUkC",
        "outputId": "4682f955-d736-47da-84fc-7607d003566a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "–ì–æ—Ç–æ–≤–æ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ:\n",
            "- merged_expressions_with_types_and_examples.xlsx\n",
            "- merged_expressions_with_types_and_examples.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(df_merged\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"expression\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"adresser la parole\",\n          \"aboyer (le chien)\",\n          \"acqu\\u00e9rir la nationalit\\u00e9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expression_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"verbal\",\n          \"nominal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"examples_joined\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Dois-je enfin lui adresser la parole ? \",\n          \"Les chiens aboient et les chats miaulent.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-07a91f7d-8427-4bc2-9ee8-9963b1748514\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>expression</th>\n",
              "      <th>expression_type</th>\n",
              "      <th>examples_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abonnement mensuel</td>\n",
              "      <td>nominal</td>\n",
              "      <td>En fait, elle paye un abonnement mensuel qui l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aboyer (le chien)</td>\n",
              "      <td>verbal</td>\n",
              "      <td>Les chiens aboient et les chats miaulent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>accent aigu</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Le roman Anna Kar√©nine s'√©crit avec un accent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>accent am√©ricain</td>\n",
              "      <td>nominal</td>\n",
              "      <td>D‚Äôabord, notre audience est Fran√ßaise √† 95%, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acquisition des connaissances</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Je m‚Äôexplique : on peut parfaitement v√©rifier ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>acqu√©rir la nationalit√©</td>\n",
              "      <td>verbal</td>\n",
              "      <td>On peut √©galement acqu√©rir la nationalit√© par ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>action humanitaire</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Connais-tu des actions humanitaires ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>activit√© humaine</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Les activit√©s humaines d√©truisent l‚Äôenvironnem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>adresser la parole</td>\n",
              "      <td>verbal</td>\n",
              "      <td>Dois-je enfin lui adresser la parole ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>agence de publicit√©</td>\n",
              "      <td>nominal</td>\n",
              "      <td>L‚Äôagence de publicit√© o√π elle commence est √† l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07a91f7d-8427-4bc2-9ee8-9963b1748514')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07a91f7d-8427-4bc2-9ee8-9963b1748514 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07a91f7d-8427-4bc2-9ee8-9963b1748514');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-32c40898-9e67-4565-bdc1-af2ff8c63dc1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32c40898-9e67-4565-bdc1-af2ff8c63dc1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-32c40898-9e67-4565-bdc1-af2ff8c63dc1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                      expression expression_type  \\\n",
              "0             abonnement mensuel         nominal   \n",
              "1              aboyer (le chien)          verbal   \n",
              "2                    accent aigu         nominal   \n",
              "3               accent am√©ricain         nominal   \n",
              "4  acquisition des connaissances         nominal   \n",
              "5        acqu√©rir la nationalit√©          verbal   \n",
              "6             action humanitaire         nominal   \n",
              "7               activit√© humaine         nominal   \n",
              "8             adresser la parole          verbal   \n",
              "9            agence de publicit√©         nominal   \n",
              "\n",
              "                                     examples_joined  \n",
              "0  En fait, elle paye un abonnement mensuel qui l...  \n",
              "1          Les chiens aboient et les chats miaulent.  \n",
              "2  Le roman Anna Kar√©nine s'√©crit avec un accent ...  \n",
              "3  D‚Äôabord, notre audience est Fran√ßaise √† 95%, d...  \n",
              "4  Je m‚Äôexplique : on peut parfaitement v√©rifier ...  \n",
              "5  On peut √©galement acqu√©rir la nationalit√© par ...  \n",
              "6              Connais-tu des actions humanitaires ?  \n",
              "7  Les activit√©s humaines d√©truisent l‚Äôenvironnem...  \n",
              "8            Dois-je enfin lui adresser la parole ?   \n",
              "9  L‚Äôagence de publicit√© o√π elle commence est √† l...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–º–µ–Ω—è–π—Ç–µ –ø—É—Ç–∏/–∏–º–µ–Ω–∞ ===\n",
        "FIRST_PATH  = \"polylex_maj.xlsx\"   # –ø–µ—Ä–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è —Å–ª–∏—è–Ω–∏—è)\n",
        "SECOND_PATH = \"polylexfle.xlsx\"          # –≤—Ç–æ—Ä–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Å –ø—Ä–∏–º–µ—Ä–∞–º–∏)\n",
        "EXPR_COL    = \"expression\"                   # –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º (–≤ –æ–±–µ–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ)\n",
        "EXAMPLE_COL = \"Exemple en contexte\" # –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ (–≤–æ –≤—Ç–æ—Ä–æ–π —Ç–∞–±–ª–∏—Ü–µ)\n",
        "TEST2_COL_1   = \"test2_1\"             # –∏–º—è –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "TEST2_COL_2   = \"test2_2\"             # –∏–º—è –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "\n",
        "# === –§—É–Ω–∫—Ü–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–±–µ–∑ unidecode) ===\n",
        "def normalize_expr(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è Unicode –∏ –ø—Ä–æ–±–µ–ª–æ–≤, –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä\n",
        "    s = unicodedata.normalize(\"NFKC\", s).strip().casefold()\n",
        "    # –°–∂–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "# === –ß—Ç–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü ===\n",
        "def read_excel_any(path: str) -> pd.DataFrame:\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}\")\n",
        "    return pd.read_excel(p)\n",
        "\n",
        "df_first  = read_excel_any(FIRST_PATH)\n",
        "df_second = read_excel_any(SECOND_PATH)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "required_cols_first = [EXPR_COL, TEST2_COL_1]\n",
        "# Add test2_2 to required columns only if it exists in the dataframe\n",
        "if TEST2_COL_2 in df_first.columns:\n",
        "    required_cols_first.append(TEST2_COL_2)\n",
        "\n",
        "for name, df, cols in [(\"–ø–µ—Ä–≤–∞—è\", df_first, required_cols_first), (\"–≤—Ç–æ—Ä–∞—è\", df_second, [EXPR_COL, EXAMPLE_COL])]:\n",
        "    for col in cols:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"–í {name} —Ç–∞–±–ª–∏—Ü–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æonne '{col}'. –ù–∞–π–¥–µ–Ω—ã: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "# === –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–µ—Ä–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ ===\n",
        "def classify_expression_type_from_test2(row):\n",
        "    \"\"\"Classifies expression as nominal or verbal based on test2_1 and test2_2 values.\"\"\"\n",
        "    test2_1_value = row.get(TEST2_COL_1)\n",
        "    test2_2_value = row.get(TEST2_COL_2)\n",
        "\n",
        "    if isinstance(test2_1_value, str):\n",
        "        if \"Test_ID_OUI\" in test2_1_value or \"Test_ID_NON\" in test2_1_value:\n",
        "            return \"nominal\"\n",
        "        elif test2_1_value.strip() == \"----------\":\n",
        "            # Check test2_2 if test2_1 is \"----------\"\n",
        "            if test2_2_value is None or (isinstance(test2_2_value, str) and not test2_2_value.strip()):\n",
        "                return \"N/A\" # Set to N/A if test2_2 is empty\n",
        "            else:\n",
        "                # If test2_2 is not empty, use the original verbal logic (or refine if needed)\n",
        "                 if isinstance(test2_2_value, str):\n",
        "                    if \"Test_ID_OUI\" in test2_2_value or \"Test_ID_NON\" in test2_2_value:\n",
        "                        return \"nominal\" # Check test2_2 for nominal indicators\n",
        "    # Default to verbal if test2_1 doesn't fit nominal criteria and test2_2 doesn't either (or doesn't exist/is empty)\n",
        "    return \"verbal\"\n",
        "\n",
        "\n",
        "# Apply the classification function row-wise\n",
        "df_first['expression_type'] = df_first.apply(classify_expression_type_from_test2, axis=1)\n",
        "\n",
        "\n",
        "# === –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –≤–æ –≤—Ç–æ—Ä–æ–π —Ç–∞–±–ª–∏—Ü–µ ===\n",
        "df_second[\"_key\"]  = df_second[EXPR_COL].apply(normalize_expr)\n",
        "\n",
        "# –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ df_second\n",
        "agg_examples = (\n",
        "    df_second[df_second[EXAMPLE_COL].notna()] # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫–æ–ª–æ–Ω–∫–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –ø—É—Å—Ç–∞\n",
        "    .groupby(\"_key\")[EXAMPLE_COL]\n",
        "    .apply(list)\n",
        "    .reset_index(name=\"examples_from_second\")\n",
        ")\n",
        "\n",
        "# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã –∏ merge ===\n",
        "# –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º df_first with the new 'expression_type' column\n",
        "df_first[\"_key\"] = df_first[EXPR_COL].apply(normalize_expr)\n",
        "\n",
        "# left join: –±–µ—Ä—ë–º –í–°–ï –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–µ—Ä–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã (–≤–∫–ª—é—á–∞—è —Ç–∏–ø), –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—Ç–æ—Ä–æ–π —Ç–∞–±–ª–∏—Ü—ã\n",
        "# Ensure TEST2_COL_2 is included if it exists in df_first for the merge step if needed for classification logic\n",
        "# But we will drop it before saving.\n",
        "cols_to_merge = [EXPR_COL, 'expression_type', \"_key\"]\n",
        "if TEST2_COL_2 in df_first.columns:\n",
        "    cols_to_merge.append(TEST2_COL_2)\n",
        "\n",
        "\n",
        "df_merged = (\n",
        "    df_first[cols_to_merge] # Include columns needed for merge and potential classification checks\n",
        "    .merge(agg_examples, on=\"_key\", how=\"left\")\n",
        "    .drop(columns=[\"_key\"])\n",
        ")\n",
        "\n",
        "# === –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É test2_2 before saving if it exists ===\n",
        "if TEST2_COL_2 in df_merged.columns:\n",
        "    df_merged = df_merged.drop(columns=[TEST2_COL_2])\n",
        "\n",
        "\n",
        "# –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É (–µ—Å–ª–∏ —É–¥–æ–±–Ω–µ–µ –¥–ª—è Excel)\n",
        "def fmt_examples(lst):\n",
        "    if not isinstance(lst, list) or len(lst) == 0:\n",
        "        return None\n",
        "    # —Ä–∞–∑–¥–µ–ª–∏–º \" | \" ‚Äî –º–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ \"\\n\" –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫\n",
        "    return \" | \".join(lst)\n",
        "\n",
        "df_merged[\"examples_joined\"] = df_merged[\"examples_from_second\"].apply(fmt_examples)\n",
        "\n",
        "# === –£–¥–∞–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –∫–æ–ª–æ–Ω–∫—É –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º ===\n",
        "df_merged = df_merged.drop(columns=[\"examples_from_second\"])\n",
        "\n",
        "\n",
        "# === –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ===\n",
        "out_xlsx = \"merged_expressions_with_types_and_examples.xlsx\" # Updated output filename\n",
        "out_csv  = \"merged_expressions_with_types_and_examples.csv\"  # Updated output filename\n",
        "df_merged.to_excel(out_xlsx, index=False)\n",
        "df_merged.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"–ì–æ—Ç–æ–≤–æ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ:\\n- {out_xlsx}\\n- {out_csv}\")\n",
        "\n",
        "# –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫\n",
        "display(df_merged.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WfoRtKQmW6W",
        "outputId": "0d1afc47-a226-4dd5-a115-52749f39d712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting 708 nominal expressions into 8 chunks.\n",
            "Saved expression_chunks/nominal/nominal_part_1.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_2.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_3.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_4.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_5.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_6.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_7.xlsx\n",
            "Saved expression_chunks/nominal/nominal_part_8.xlsx\n",
            "Finished splitting nominal expressions.\n",
            "Splitting 414 verbal expressions into 5 chunks.\n",
            "Saved expression_chunks/verbal/verbal_part_1.xlsx\n",
            "Saved expression_chunks/verbal/verbal_part_2.xlsx\n",
            "Saved expression_chunks/verbal/verbal_part_3.xlsx\n",
            "Saved expression_chunks/verbal/verbal_part_4.xlsx\n",
            "Saved expression_chunks/verbal/verbal_part_5.xlsx\n",
            "Finished splitting verbal expressions.\n",
            "\n",
            "Finished splitting all expressions into nominal and verbal chunks.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Assuming df_merged is already loaded from a previous step and contains 'expression_type'\n",
        "\n",
        "# Define the number of rows per chunk\n",
        "chunk_size = 100\n",
        "\n",
        "# Create directories to save the chunks if they don't exist\n",
        "nominal_chunks_dir = \"expression_chunks/nominal\"\n",
        "verbal_chunks_dir = \"expression_chunks/verbal\"\n",
        "\n",
        "if not os.path.exists(nominal_chunks_dir):\n",
        "    os.makedirs(nominal_chunks_dir)\n",
        "if not os.path.exists(verbal_chunks_dir):\n",
        "    os.makedirs(verbal_chunks_dir)\n",
        "\n",
        "# Split the DataFrame into nominal and verbal\n",
        "df_nominal = df_merged[df_merged['expression_type'] == 'nominal'].copy()\n",
        "df_verbal = df_merged[df_merged['expression_type'] == 'verbal'].copy()\n",
        "df_n_a = df_merged[df_merged['expression_type'] == 'N/A'].copy()\n",
        "\n",
        "\n",
        "# Function to split a DataFrame into chunks and save\n",
        "def split_and_save_chunks(df, output_dir, type_name):\n",
        "    num_chunks = math.ceil(len(df) / chunk_size)\n",
        "    print(f\"Splitting {len(df)} {type_name} expressions into {num_chunks} chunks.\")\n",
        "    for i in range(num_chunks):\n",
        "        start_row = i * chunk_size\n",
        "        end_row = (i + 1) * chunk_size\n",
        "        df_chunk = df.iloc[start_row:end_row]\n",
        "\n",
        "        output_filename = os.path.join(output_dir, f\"{type_name}_part_{i+1}.xlsx\")\n",
        "        df_chunk.to_excel(output_filename, index=False)\n",
        "        print(f\"Saved {output_filename}\")\n",
        "    print(f\"Finished splitting {type_name} expressions.\")\n",
        "\n",
        "\n",
        "# Split and save nominal chunks\n",
        "split_and_save_chunks(df_nominal, nominal_chunks_dir, \"nominal\")\n",
        "\n",
        "# Split and save verbal chunks\n",
        "split_and_save_chunks(df_verbal, verbal_chunks_dir, \"verbal\")\n",
        "\n",
        "# Handle N/A entries (optional: save them or print a message)\n",
        "if not df_n_a.empty:\n",
        "    print(f\"\\nFound {len(df_n_a)} expressions classified as N/A. These were not chunked with nominal or verbal.\")\n",
        "    # Optional: Save N/A entries to a separate file\n",
        "    # df_n_a.to_excel(\"expression_chunks/n_a_expressions.xlsx\", index=False)\n",
        "    # print(\"Saved N/A expressions to expression_chunks/n_a_expressions.xlsx\")\n",
        "\n",
        "print(\"\\nFinished splitting all expressions into nominal and verbal chunks.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install anthropic\n",
        "\n",
        "from anthropic import Anthropic\n",
        "\n",
        "# =========================\n",
        "# 0. CLIENT (Claude via Anthropic API)\n",
        "# =========================\n",
        "client = Anthropic(api_key=\"\")\n",
        "\n",
        "# =========================\n",
        "# 1. –ú–û–î–ï–õ–¨\n",
        "# =========================\n",
        "# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å snapshot –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏:\n",
        "MODEL_NAME = \"claude-opus-4-5-20251101\"\n",
        "# –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å alias (–º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º):\n",
        "# MODEL_NAME = \"claude-sonnet-4-5\"\n",
        "\n",
        "# =========================\n",
        "# 2. RETRY / THROTTLE (–Ω–∞ —Å–ª—É—á–∞–π 429/529 –∏ —Ç.–ø.)\n",
        "# =========================\n",
        "MAX_RETRIES = 7\n",
        "MAX_BACKOFF_SEC = 30.0\n",
        "THROTTLE_PER_CALL_SEC = 0.15  # –µ—Å–ª–∏ –ª–æ–≤–∏—à—å 429/529 —á–∞—Å—Ç–æ ‚Üí 0.25‚Äì0.4\n",
        "\n",
        "def _is_retryable(exc: Exception) -> bool:\n",
        "    # Anthropic SDK –æ–±—ã—á–Ω–æ –∫–ª–∞–¥–µ—Ç status_code –≤ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ (–∏–ª–∏ –≤ str)\n",
        "    msg = str(exc).lower()\n",
        "    return (\n",
        "        \"429\" in msg\n",
        "        or \"rate\" in msg\n",
        "        or \"529\" in msg\n",
        "        or \"overloaded\" in msg\n",
        "        or \"503\" in msg\n",
        "        or \"unavailable\" in msg\n",
        "        or \"timeout\" in msg\n",
        "    )\n",
        "\n",
        "def _extract_text(message) -> str:\n",
        "    \"\"\"\n",
        "    message.content –æ–±—ã—á–Ω–æ —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ (TextBlock –∏ —Ç.–ø.).\n",
        "    –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    try:\n",
        "        for block in message.content:\n",
        "            # SDK-–æ–±—ä–µ–∫—Ç—ã\n",
        "            if hasattr(block, \"type\") and block.type == \"text\" and hasattr(block, \"text\"):\n",
        "                parts.append(block.text)\n",
        "            # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Å–ª–æ–≤–∞—Ä–∏\n",
        "            elif isinstance(block, dict) and block.get(\"type\") == \"text\":\n",
        "                parts.append(block.get(\"text\", \"\"))\n",
        "    except Exception:\n",
        "        # fallback\n",
        "        if hasattr(message, \"content\") and isinstance(message.content, str):\n",
        "            parts.append(message.content)\n",
        "    return \"\".join(parts).strip()\n",
        "\n",
        "def create_message_with_retry(prompt: str, max_tokens: int = 40, temperature: float = 0.0) -> str:\n",
        "    last_exc = None\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            msg = client.messages.create(\n",
        "                model=MODEL_NAME,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            )\n",
        "            text = _extract_text(msg)\n",
        "            time.sleep(THROTTLE_PER_CALL_SEC)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            if _is_retryable(e):\n",
        "                wait = min(MAX_BACKOFF_SEC, (2 ** attempt) + random.uniform(0, 1))\n",
        "                print(f\"‚ö†Ô∏è Retryable API error ‚Äî retry in {wait:.1f}s ({attempt+1}/{MAX_RETRIES})\")\n",
        "                time.sleep(wait)\n",
        "                continue\n",
        "            raise\n",
        "    raise RuntimeError(f\"√âchec apr√®s {MAX_RETRIES} retries. Derni√®re erreur: {last_exc}\")\n",
        "\n",
        "# =========================\n",
        "# 3. PROMPTS DES TESTS (SANS FEW-SHOT) ‚Äî –ù–ï –ú–ï–ù–Ø–ï–ú\n",
        "# =========================\n",
        "\n",
        "CRAN_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST CRAN ‚Äî mot exclusivement fig√©\n",
        "Question : l‚Äôexpression contient-elle un mot exclusivement fig√© ?\n",
        "\n",
        "Un mot exclusivement fig√© :\n",
        "- n‚Äôexiste pas comme mot autonome,\n",
        "- n‚Äôappara√Æt jamais en dehors de l‚Äôexpression,\n",
        "- n‚Äôa plus d‚Äôusage productif moderne.\n",
        "\n",
        "Exemple OUI : ¬´ us ¬ª dans ¬´ us et coutumes ¬ª\n",
        "Exemple NON : ¬´ bleu ¬ª dans ¬´ cordon bleu ¬ª\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "MORPH_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST MORPH ‚Äî modification morphologique\n",
        "Question : la flexion (pluriel, genre) rend-elle l‚Äôexpression agrammaticale ou √©trange ?\n",
        "\n",
        "Exemple OUI : ¬´ garde du corps ¬ª ‚Üí ¬´ gardes du corps ¬ª\n",
        "Exemple NON : ¬´ livre scolaire ¬ª ‚Üí ¬´ livres scolaires ¬ª\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "SYNT_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST SYNT ‚Äî modification syntaxique\n",
        "Question : un changement d‚Äôordre ou de structure modifie-t-il fortement le sens ou le rend-il agrammaticale ou bizzare ?\n",
        "\n",
        "Exemple OUI : ¬´ pomme de terre ¬ª ‚â† ¬´ pomme terrestre ¬ª\n",
        "Exemple NON : ¬´ comit√© r√©gional ¬ª ‚âà ¬´ comit√© de la r√©gion ¬ª\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "LEX_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST LEX ‚Äî substitution lexicale\n",
        "Question : remplacer un √©l√©ment par un synonyme rend-il l‚Äôexpression anormale, agrammaticale ou bizzare ?\n",
        "\n",
        "Exemple OUI : ¬´ eau de vie ¬ª ‚Üí ¬´ boisson de vie ¬ª\n",
        "Exemple NON : ¬´ prix r√©duit ¬ª ‚Üí ¬´ tarif r√©duit ¬ª\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "MODIF_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST MODIF ‚Äî insertion d‚Äôun modifieur\n",
        "Question : l‚Äôinsertion d‚Äôun modifieur (adjectif/adverbe) interne rend-elle l‚Äôexpression anormale, agrammaticale ou bizzare ?\n",
        "\n",
        "Exemple OUI : ¬´ pomme verte de terre ¬ª\n",
        "Exemple NON : ¬´ roman contemporain policier ¬ª\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "SEMREST_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST SEM-REST ‚Äî restrictions s√©mantiques\n",
        "Question : la t√™te nominale (le nom principal de l'expression) telle qu'elle est utilis√©e dans cette expression (dans son sens contextuel) a-t-elle un ensemble restreint de collocatifs naturels ?\n",
        "\n",
        "Exemple OUI : ¬´ professeur de linguistique ¬ª ‚Üí mais aussi ¬´ professeur de maths ¬ª, ¬´ professeur de chimie ¬ª, ¬´ professeur de litt√©rature ¬ª (ensemble restreint aux domaines acad√©miques)\n",
        "Exemple NON : ¬´ √©v√©nement majeur ¬ª ‚Üí mais aussi ¬´ √©v√©nement local ¬ª, ¬´ √©v√©nement impr√©vu ¬ª, ¬´ √©v√©nement politique ¬ª, etc. (ensemble tr√®s ouvert)\n",
        "\n",
        "‚ö†Ô∏è Attention : Tu dois analyser UNIQUEMENT la t√™te nominale, pas l‚Äôexpression enti√®re.\n",
        "On v√©rifie avec quels collocatifs naturels se combine la t√™te nominale seule.\n",
        "\n",
        "Exemples :\n",
        "- dans ¬´ roman policier ¬ª ‚Üí la t√™te nominale = ¬´ roman ¬ª, pas ¬´ roman policier ¬ª\n",
        "- dans ¬´ pomme de terre ¬ª ‚Üí la t√™te nominale = ¬´ pomme ¬ª, pas ¬´ pomme de terre ¬ª\n",
        "\n",
        "Ne prends jamais l‚Äôexpression compl√®te comme base de comparaison.\n",
        "Toujours la t√™te nominale seule.\n",
        "\n",
        "‚ö†Ô∏è Attention : Dans ces donn√©es, il est rare que la r√©ponse √† ce test est NON.\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "ID_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "TEST ID ‚Äî type naturel\n",
        "Question : l‚Äôexpression d√©signe-t-elle une sous-cat√©gorie naturelle et litt√©rale du noyau nominal ?\n",
        "\n",
        "\n",
        "‚ö†Ô∏è Attention : tu dois identifier la t√™te syntaxique de l‚Äôexpression :\n",
        "le nom qui constitue le noyau de la construction nominale. L‚Äôobjectif du test est de d√©terminer si l‚Äôexpression d√©signe une sous-cat√©gorie\n",
        "naturelle de ce noyau.\n",
        "\n",
        "Pour r√©pondre OUI, le noyau nominal doit garder son sens litt√©ral et l‚Äôexpression doit d√©signer un type de ce nom. La r√©ponse est plus souvent OUI que NON, donc dans les cas d'incertitude penche vers OUI.\n",
        "\n",
        "Exemples ID = NON :\n",
        "- ¬´ √Æle flottante ¬ª (dessert) : ce n‚Äôest pas un type d'√Æle, c'est un dessert\n",
        "- ¬´ for√™t noire ¬ª (g√¢teau) : ce n‚Äôest pas un type de for√™t, c'est un g√¢teau\n",
        "\n",
        "Exemple ID = OUI :\n",
        "- ¬´ √©v√©nement culturel ¬ª : c‚Äôest un type d‚Äô√©v√©nement\n",
        "- ¬´ chaise en bois ¬ª : c‚Äôest un type de chaise\n",
        "- ¬´ v√©hicule √©lectrique ¬ª : c‚Äôest un type de v√©hicule\n",
        "- ¬´ bouteille en plastique ¬ª : c‚Äôest un type de bouteille\n",
        "- ¬´ porte coulissante ¬ª : c‚Äôest un type de porte\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "OPAC_PROMPT = \"\"\"\n",
        "Tu es linguiste annotateur. R√©ponds UNIQUEMENT par \"OUI\" ou \"NON\".\n",
        "\n",
        "üîµ TEST OPAC ‚Äî opacit√© s√©mantique\n",
        "\n",
        "Question : le sens global ne correspond-il pas √† la somme des sens litt√©raux des composants ?\n",
        "\n",
        "Si le noyau nominal n‚Äôest pas litt√©ral ‚Üí OPAC = OUI.\n",
        "\n",
        "Exemples OUI :\n",
        "- ¬´ √Æle flottante ¬ª (pas une √Æle qui flotte)\n",
        "- ¬´ for√™t noire ¬ª (pas une for√™t qui est noire)\n",
        "- ¬´ lune de miel ¬ª (pas une lune construite de miel)\n",
        "\n",
        "Exemples NON :\n",
        "- ¬´ analyse des donn√©es ¬ª (c'est une analyse impliquant des donn√©es)\n",
        "- ¬´ d√©cision administrative ¬ª (c'est une d√©cision qui est de type administratif)\n",
        "\n",
        "Expression : ¬´ {expression} ¬ª\n",
        "Contexte : {contexte}\n",
        "\n",
        "R√©ponds uniquement OUI ou NON.\n",
        "Puis ajoute UNE phrase tr√®s courte expliquant la raison.\n",
        "Format obligatoire :\n",
        "OUI/NON\n",
        "Explication : <phrase tr√®s courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "# =========================\n",
        "# 4. APPEL D‚ÄôUN TEST\n",
        "# =========================\n",
        "\n",
        "def ask_test(prompt_template, expression, examples):\n",
        "    contexte = \"\" if examples is None or pd.isna(examples) else str(examples)\n",
        "\n",
        "    prompt = prompt_template.format(\n",
        "        expression=expression,\n",
        "        contexte=contexte\n",
        "    )\n",
        "\n",
        "    full = create_message_with_retry(prompt, max_tokens=40, temperature=0.0)\n",
        "\n",
        "    first_line = full.split(\"\\n\")[0].strip().upper() if full else \"\"\n",
        "    decision = \"OUI\" if first_line == \"OUI\" else \"NON\"\n",
        "\n",
        "    explanation = \"\"\n",
        "    if \"\\n\" in full:\n",
        "        explanation = full.split(\"\\n\", 1)[1].strip()\n",
        "\n",
        "    return decision, explanation\n",
        "\n",
        "# =========================\n",
        "# 5. –î–ï–†–ï–í–û –†–ï–®–ï–ù–ò–ô\n",
        "# =========================\n",
        "\n",
        "def annotate_expression(expression, examples):\n",
        "    tests = {}\n",
        "\n",
        "    d, e = ask_test(CRAN_PROMPT, expression, examples)\n",
        "    tests[\"CRAN\"] = (d, e)\n",
        "    if d == \"OUI\":\n",
        "        return tests, \"expression_idiomatique\"\n",
        "\n",
        "    d, e = ask_test(MORPH_PROMPT, expression, examples)\n",
        "    tests[\"MORPH\"] = (d, e)\n",
        "    if d == \"OUI\":\n",
        "        d2, e2 = ask_test(ID_PROMPT, expression, examples)\n",
        "        tests[\"ID\"] = (d2, e2)\n",
        "        if d2 == \"NON\":\n",
        "            return tests, \"expression_idiomatique\"\n",
        "        d3, e3 = ask_test(OPAC_PROMPT, expression, examples)\n",
        "        tests[\"OPAC\"] = (d3, e3)\n",
        "        return tests, \"collocation_opaque\" if d3 == \"OUI\" else \"collocation_transparente\"\n",
        "\n",
        "    d, e = ask_test(SYNT_PROMPT, expression, examples)\n",
        "    tests[\"SYNT\"] = (d, e)\n",
        "    if d == \"OUI\":\n",
        "        d2, e2 = ask_test(ID_PROMPT, expression, examples)\n",
        "        tests[\"ID\"] = (d2, e2)\n",
        "        if d2 == \"NON\":\n",
        "            return tests, \"expression_idiomatique\"\n",
        "        d3, e3 = ask_test(OPAC_PROMPT, expression, examples)\n",
        "        tests[\"OPAC\"] = (d3, e3)\n",
        "        return tests, \"collocation_opaque\" if d3 == \"OUI\" else \"collocation_transparente\"\n",
        "\n",
        "    d, e = ask_test(LEX_PROMPT, expression, examples)\n",
        "    tests[\"LEX\"] = (d, e)\n",
        "    if d == \"OUI\":\n",
        "        d2, e2 = ask_test(ID_PROMPT, expression, examples)\n",
        "        tests[\"ID\"] = (d2, e2)\n",
        "        if d2 == \"NON\":\n",
        "            return tests, \"expression_idiomatique\"\n",
        "        d3, e3 = ask_test(OPAC_PROMPT, expression, examples)\n",
        "        tests[\"OPAC\"] = (d3, e3)\n",
        "        return tests, \"collocation_opaque\" if d3 == \"OUI\" else \"collocation_transparente\"\n",
        "\n",
        "    d, e = ask_test(MODIF_PROMPT, expression, examples)\n",
        "    tests[\"MODIF\"] = (d, e)\n",
        "    if d == \"OUI\":\n",
        "        d2, e2 = ask_test(ID_PROMPT, expression, examples)\n",
        "        tests[\"ID\"] = (d2, e2)\n",
        "        if d2 == \"NON\":\n",
        "            return tests, \"expression_idiomatique\"\n",
        "        d3, e3 = ask_test(OPAC_PROMPT, expression, examples)\n",
        "        tests[\"OPAC\"] = (d3, e3)\n",
        "        return tests, \"collocation_opaque\" if d3 == \"OUI\" else \"collocation_transparente\"\n",
        "\n",
        "    d, e = ask_test(SEMREST_PROMPT, expression, examples)\n",
        "    tests[\"SEM-REST\"] = (d, e)\n",
        "    if d == \"NON\":\n",
        "        return tests, \"expression_libre\"\n",
        "\n",
        "    d, e = ask_test(ID_PROMPT, expression, examples)\n",
        "    tests[\"ID\"] = (d, e)\n",
        "    if d == \"NON\":\n",
        "        return tests, \"expression_idiomatique\"\n",
        "\n",
        "    d, e = ask_test(OPAC_PROMPT, expression, examples)\n",
        "    tests[\"OPAC\"] = (d, e)\n",
        "    return tests, \"collocation_opaque\" if d == \"OUI\" else \"collocation_transparente\"\n",
        "\n",
        "# =========================\n",
        "# 6. FORMAT llm_raw_response\n",
        "# =========================\n",
        "\n",
        "def generate_annotation_with_llm(expression, examples):\n",
        "    tests, category = annotate_expression(expression, examples)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"CAT√âGORIE FINALE : {category}\")\n",
        "    lines.append(\"Explications des tests :\")\n",
        "\n",
        "    for t in [\"CRAN\", \"MORPH\", \"SYNT\", \"LEX\", \"MODIF\", \"SEM-REST\", \"ID\", \"OPAC\"]:\n",
        "        if t in tests:\n",
        "            d, e = tests[t]\n",
        "            lines.append(f\"{t} : {d}\")\n",
        "            if e:\n",
        "                lines.append(f\"  Explication : {e}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# =========================\n",
        "# 7. TRAITEMENT EXCEL\n",
        "# =========================\n",
        "\n",
        "input_file = \"nominal_part_7.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "df[\"llm_raw_response\"] = None\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Annotation EP (Claude)\"):\n",
        "    expr = row.get(\"expression\")\n",
        "    ex = row.get(\"examples_joined\")\n",
        "\n",
        "    if pd.isna(expr) or not str(expr).strip():\n",
        "        df.at[idx, \"llm_raw_response\"] = \"N/A\"\n",
        "        continue\n",
        "\n",
        "    df.at[idx, \"llm_raw_response\"] = generate_annotation_with_llm(expr, ex)\n",
        "\n",
        "output_file = \"annotated_nominal_part_7_claude_opus45_tests.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Saved: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC1cF1QA8uKw",
        "outputId": "2ef6f199-af4e-4b15-d043-dd6f23b2aa9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (0.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotation EP (Claude): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [41:16<00:00, 24.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: annotated_nominal_part_7_claude_opus45_tests.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ckWUTzrj6239"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "601b8adf"
      },
      "source": [
        "# Task\n",
        "Annotate expressions from the \"merged_expressions_with_examples.xlsx\" file using a Hugging Face LLM. The LLM should be prompted with information from \"guide_EP_nominales.pdf\" or \"guide_EP_verbales.pdf\" based on whether the expression is nominal or verbal. The output should be a table in the format of \"PolyLexFLE - majorit√©.xlsx\", including the expression, its type, the results of three tests, and the LLM model name as the annotator. Do not use the \"PolyLexFLE - majorit√©.xlsx\" file for annotation, only for formatting the output. Use only the prompts based on the guides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83fc6fbb"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install the `transformers` library and any other required dependencies for using Hugging Face models and handling PDF files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b160aefa"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing Python libraries for Hugging Face models and PDF processing. I will use `pip` to install the `transformers` and `pdfminer.six` libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf05192d"
      },
      "source": [
        "## Initialize hugging face llm\n",
        "\n",
        "### Subtask:\n",
        "Load a suitable LLM from the Hugging Face `transformers` library. Consider the model size and computational resources available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99d4e545"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the tokenizer and the model from the Hugging Face transformers library based on the chosen model name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "glKpvu_w-fBu",
        "outputId": "dbc08a5f-acec-4958-9313-e6d8b7102b6e"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'llm_raw_response'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'llm_raw_response'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4062677258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_chunk[df_chunk[\"llm_raw_response\"].str.startswith((\"N/A\", \"Skipped\"))][\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"expression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expression_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"llm_raw_response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ].head(20)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'llm_raw_response'"
          ]
        }
      ],
      "source": [
        "df_chunk[df_chunk[\"llm_raw_response\"].str.startswith((\"N/A\", \"Skipped\"))][\n",
        "    [\"expression\", \"expression_type\", \"llm_raw_response\"]\n",
        "].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMXW7wCa3IrE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "851d8d22"
      },
      "source": [
        "## Parse LLM Output\n",
        "\n",
        "### Subtask:\n",
        "Parse the `llm_raw_response` column in the annotated DataFrame to extract the annotation type, the three main test results, and the justification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39k3cDwoPsLp"
      },
      "outputs": [],
      "source": [
        "4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3bbfb73"
      },
      "source": [
        "**Reasoning**:\n",
        "The LLM output is in a specific format that includes the annotation type, test results, and justification. I will extract this information from the `llm_raw_response` column and create new columns in the DataFrame to store the parsed data. I will use regular expressions and string manipulation to extract the relevant parts of the text based on the structure defined in the prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ca91eca"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_llm_output(raw_response):\n",
        "    \"\"\"\n",
        "    Parses the raw LLM response string to extract annotation type, tests, and justification.\n",
        "    Assumes the response follows the structure defined in the prompts.\n",
        "    \"\"\"\n",
        "    parsed_data = {\n",
        "        'llm_annotation_type': 'Parsing Error',\n",
        "        'llm_justification': 'Parsing Error',\n",
        "        'test1_name': 'N/A', 'test1_result': 'N/A', 'test1_explanation': '',\n",
        "        'test2_name': 'N/A', 'test2_result': 'N/A', 'test2_explanation': '',\n",
        "        'test3_name': 'N/A', 'test3_result': 'N/A', 'test3_explanation': ''\n",
        "    }\n",
        "\n",
        "    if not isinstance(raw_response, str):\n",
        "        return parsed_data\n",
        "\n",
        "    # Extract Expression Type\n",
        "    type_match = re.search(r\"Type d‚Äôexpression finale\\s*[‚à∂:]\\s*(.*?)\\n\", raw_response)\n",
        "    if type_match:\n",
        "        parsed_data['llm_annotation_type'] = type_match.group(1).strip()\n",
        "    else:\n",
        "         # Try alternative pattern for verbal prompt\n",
        "        type_match = re.search(r\"Le type d‚Äôexpression finale, parmi\\s*[‚à∂:]\\s*(.*?)\\n\", raw_response)\n",
        "        if type_match:\n",
        "            # Extract the first type listed if multiple are present (common in verbal prompt examples)\n",
        "            types_list = type_match.group(1).strip().split('\\n')[0]\n",
        "            parsed_data['llm_annotation_type'] = types_list.split(',')[0].strip() # Take the first one before comma if multiple listed\n",
        "\n",
        "    # Extract Justification\n",
        "    justification_match = re.search(r\"Justification finale\\s*\\(2‚Äì3 phrases\\)\\s*[:‚à∂](.*?)(?:\\n\\n|\\Z)\", raw_response, re.DOTALL)\n",
        "    if justification_match:\n",
        "        parsed_data['llm_justification'] = justification_match.group(1).strip()\n",
        "    else:\n",
        "         # Try alternative pattern for verbal prompt\n",
        "        justification_match = re.search(r\"Une justification synth√©tique\\s*\\(2‚Äì3 phrases\\)\\s*[:‚à∂](.*?)(?:\\n\\n|\\Z)\", raw_response, re.DOTALL)\n",
        "        if justification_match:\n",
        "             parsed_data['llm_justification'] = justification_match.group(1).strip()\n",
        "\n",
        "\n",
        "    # Extract Test Results (assuming up to 3 tests are explicitly mentioned or can be extracted sequentially)\n",
        "    # This part might need refinement based on actual LLM output format for tests\n",
        "\n",
        "    # Simple approach: find lines starting with \"TEST X\" or similar patterns and extract info\n",
        "    test_lines = re.findall(r\"(TEST \\d+ ‚Äî.*?)(?=\\nTEST \\d+ ‚Äî|\\n\\n)\", raw_response, re.DOTALL)\n",
        "\n",
        "    # If nominal prompt structure is followed with numbered tests and details\n",
        "    if \"R√©sultats des tests (1 √† 15)\" in raw_response:\n",
        "        test_blocks = re.findall(r\"### TEST (\\d+)\\s*‚Äî\\s*(.*?)\\n(.*?)(?=\\n### TEST \\d+ ‚Äî|\\n\\n)\", raw_response, re.DOTALL)\n",
        "        for i, block in enumerate(test_blocks[:3]): # Take up to the first 3 detailed test blocks\n",
        "            test_num, test_name_full, test_details = block\n",
        "            test_name = test_name_full.strip()\n",
        "\n",
        "            # Extract result (OUI/NON)\n",
        "            result_match = re.search(r\"r√©sultat\\s*[:‚à∂]\\s*\\\"(OUI|NON)\\\"\", test_details)\n",
        "            test_result = result_match.group(1) if result_match else 'N/A'\n",
        "\n",
        "            # Extract explanation\n",
        "            explanation_match = re.search(r\"explication\\s*[:‚à∂]\\s*(.*?)(?:\\n|$)\", test_details)\n",
        "            test_explanation = explanation_match.group(1).strip() if explanation_match else ''\n",
        "\n",
        "            parsed_data[f'test{i+1}_name'] = f'TEST {test_num} - {test_name}'\n",
        "            parsed_data[f'test{i+1}_result'] = test_result\n",
        "            parsed_data[f'test{i+1}_explanation'] = test_explanation\n",
        "\n",
        "    # If verbal prompt structure is followed (simpler test format)\n",
        "    elif \"Les trois tests principaux qui ont d√©termin√© ton raisonnement\" in raw_response:\n",
        "         test_entries = re.findall(r\"- test:\\s*(.*?)\\n\\s*reponse:\\s*(.*?)(?:\\n\\s*justification:\\s*(.*?))?(?=\\n- test:|\\Z)\", raw_response, re.DOTALL)\n",
        "         for i, entry in enumerate(test_entries[:3]): # Take up to the first 3 test entries\n",
        "            test_name, test_result, test_justification = entry\n",
        "            parsed_data[f'test{i+1}_name'] = test_name.strip()\n",
        "            parsed_data[f'test{i+1}_result'] = test_result.strip()\n",
        "            parsed_data[f'test{i+1}_explanation'] = test_justification.strip() if test_justification else ''\n",
        "\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "# Apply the parsing function to the 'llm_raw_response' column of the df_annotated_chunk DataFrame\n",
        "parsed_data = df_annotated_chunk['llm_raw_response'].apply(parse_llm_output)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df_parsed_data = pd.DataFrame(list(parsed_data))\n",
        "\n",
        "# Concatenate the original DataFrame with the parsed data\n",
        "df_annotated_parsed = pd.concat([df_annotated_chunk, df_parsed_data], axis=1)\n",
        "\n",
        "# Display the relevant columns of the resulting DataFrame\n",
        "display(df_annotated_parsed[['expression', 'expression_type', 'llm_annotation_type', 'llm_justification',\n",
        "                             'test1_name', 'test1_result', 'test1_explanation',\n",
        "                             'test2_name', 'test2_result', 'test2_explanation',\n",
        "                             'test3_name', 'test3_result', 'test3_explanation']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb0fc756"
      },
      "source": [
        "## Format Output Table\n",
        "\n",
        "### Subtask:\n",
        "Create a new DataFrame with the required columns in the format of \"PolyLexFLE - majorit√©.xlsx\", including the original expression, its type, the parsed LLM annotation and test results, and the LLM model name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1df5d71d"
      },
      "source": [
        "**Reasoning**:\n",
        "The final output needs to be in a specific table format. I will select and rename the relevant columns from the `df_annotated_parsed` DataFrame to match the desired output structure. I will also add a column for the LLM model name used for annotation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32902e29"
      },
      "outputs": [],
      "source": [
        "# Define the desired output column names based on \"PolyLexFLE - majorit√©.xlsx\" format\n",
        "output_columns = {\n",
        "    'expression': 'Expression',\n",
        "    'expression_type': 'Type Original', # Original type from the input data\n",
        "    'llm_annotation_type': 'Type Annotation LLM', # Annotation provided by the LLM\n",
        "    'test1_name': 'Test 1 Nom',\n",
        "    'test1_result': 'Test 1 R√©sultat',\n",
        "    'test1_explanation': 'Test 1 Explication',\n",
        "    'test2_name': 'Test 2 Nom',\n",
        "    'test2_result': 'Test 2 R√©sultat',\n",
        "    'test2_explanation': 'Test 2 Explication',\n",
        "    'test3_name': 'Test 3 Nom',\n",
        "    'test3_result': 'Test 3 R√©sultat',\n",
        "    'test3_explanation': 'Test 3 Explication',\n",
        "    'llm_justification': 'Justification LLM',\n",
        "    # Add other columns from the target format if needed, mapped from df_annotated_parsed\n",
        "}\n",
        "\n",
        "# Create the final output DataFrame by selecting and renaming columns\n",
        "df_final_output = df_annotated_parsed.rename(columns=output_columns)[list(output_columns.values())]\n",
        "\n",
        "# Add a column for the LLM Model Name\n",
        "llm_model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # Replace with the actual model ID used\n",
        "df_final_output['Annotateur'] = llm_model_name\n",
        "\n",
        "# Display the first few rows of the final output DataFrame\n",
        "display(df_final_output.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab28d040"
      },
      "source": [
        "## Save Results\n",
        "\n",
        "### Subtask:\n",
        "Save the resulting DataFrame to a new Excel file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e34ba49"
      },
      "source": [
        "**Reasoning**:\n",
        "The final step is to save the DataFrame containing the formatted LLM annotations to an Excel file for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ac603c0"
      },
      "outputs": [],
      "source": [
        "# Save the formatted annotations to an Excel file\n",
        "output_excel_path = \"llm_annotations.xlsx\"\n",
        "df_final_output.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"LLM annotations saved to: {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ce4d7c"
      },
      "source": [
        "## Parse LLM Output\n",
        "\n",
        "### Subtask:\n",
        "Parse the `llm_raw_response` column in the annotated DataFrame to extract the annotation type, the three main test results, and the justification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff3c446d"
      },
      "source": [
        "**Reasoning**:\n",
        "\n",
        "The LLM output is in JSON format embedded within a string. I need to extract this JSON string, parse it, and then extract the relevant information (annotation, tests, rationale) to populate new columns in the DataFrame. I will use the `json` library to parse the JSON and handle potential errors during parsing. I will also add columns for each of the three main tests and their explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76398c9a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df_annotated_chunk is the DataFrame with the 'llm_raw_response' column from the previous step\n",
        "\n",
        "def parse_llm_annotation(raw_response):\n",
        "    \"\"\"\n",
        "    Parses the raw LLM response string to extract annotation, tests, and rationale.\n",
        "    Assumes the response contains a JSON structure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to find and parse the JSON string\n",
        "        json_match = re.search(r'\\{.*\\}', raw_response, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_string = json_match.group(0)\n",
        "            # Clean up potential extra characters around the JSON\n",
        "            json_string = json_string.strip()\n",
        "            annotation_data = json.loads(json_string)\n",
        "\n",
        "            # Extract data\n",
        "            annotation = annotation_data.get('annotation', 'Parsing Error: Missing annotation')\n",
        "            rationale = annotation_data.get('rationale', 'Parsing Error: Missing rationale')\n",
        "            tests = annotation_data.get('tests', [])\n",
        "\n",
        "            # Extract test results and explanations (assuming up to 3 tests as per prompt)\n",
        "            test_results = {}\n",
        "            for i in range(min(len(tests), 3)):\n",
        "                test = tests[i]\n",
        "                test_name = test.get('name', f'Test_{i+1}')\n",
        "                test_response = test.get('reponse', 'N/A')\n",
        "                test_justification = test.get('justification', '')\n",
        "                test_results[f'test{i+1}_name'] = test_name\n",
        "                test_results[f'test{i+1}_result'] = test_response\n",
        "                test_results[f'test{i+1}_explanation'] = test_justification\n",
        "\n",
        "            return {\n",
        "                'llm_annotation': annotation,\n",
        "                'llm_rationale': rationale,\n",
        "                **test_results # Include test results in the dictionary\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'llm_annotation': 'Parsing Error: No JSON found',\n",
        "                'llm_rationale': 'Parsing Error: No JSON found',\n",
        "                'test1_name': 'N/A', 'test1_result': 'N/A', 'test1_explanation': '',\n",
        "                'test2_name': 'N/A', 'test2_result': 'N/A', 'test2_explanation': '',\n",
        "                'test3_name': 'N/A', 'test3_result': 'N/A', 'test3_explanation': ''\n",
        "            }\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\n",
        "            'llm_annotation': f'Parsing Error: JSON Decode Error - {e}',\n",
        "            'llm_rationale': f'Parsing Error: JSON Decode Error - {e}',\n",
        "            'test1_name': 'N/A', 'test1_result': 'N/A', 'test1_explanation': '',\n",
        "            'test2_name': 'N/A', 'test2_result': 'N/A', 'test2_explanation': '',\n",
        "            'test3_name': 'N/A', 'test3_result': 'N/A', 'test3_explanation': ''\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'llm_annotation': f'Parsing Error: Unexpected Error - {e}',\n",
        "            'llm_rationale': f'Parsing Error: Unexpected Error - {e}',\n",
        "            'test1_name': 'N/A', 'test1_result': 'N/A', 'test1_explanation': '',\n",
        "            'test2_name': 'N/A', 'test2_result': 'N/A', 'test2_explanation': '',\n",
        "            'test3_name': 'N/A', 'test3_result': 'N/A', 'test3_explanation': ''\n",
        "        }\n",
        "\n",
        "# Apply the parsing function to the 'llm_raw_response' column\n",
        "parsed_data = df_annotated_chunk['llm_raw_response'].apply(parse_llm_annotation)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df_parsed_data = pd.DataFrame(list(parsed_data))\n",
        "\n",
        "# Concatenate the original DataFrame with the parsed data\n",
        "df_annotated_parsed = pd.concat([df_annotated_chunk, df_parsed_data], axis=1)\n",
        "\n",
        "# Display the relevant columns of the resulting DataFrame\n",
        "display(df_annotated_parsed[['expression', 'expression_type', 'llm_annotation', 'llm_rationale',\n",
        "                             'test1_name', 'test1_result', 'test1_explanation',\n",
        "                             'test2_name', 'test2_result', 'test2_explanation',\n",
        "                             'test3_name', 'test3_result', 'test3_explanation']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b8627a7"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"annotation\": \"<Expression_idiomatique | Collocation_verbale | Expression_libre | Autre>\",\n",
        "  \"tests\": [\n",
        "    {\"name\": \"Test_1\", \"result\": \"<nom_test>_<OUI|NON>\", \"explanation\": \"phrase courte expliquant le r√©sultat\"},\n",
        "    {\"name\": \"Test_2\", \"result\": \"<nom_test>_<OUI|NON>\", \"explanation\": \"phrase courte expliquant le r√©sultat\"},\n",
        "    {\"name\": \"Test_3\", \"result\": \"<nom_test>_<OUI|NON>\", \"explanation\": \"phrase courte expliquant le r√©sultat\"}\n",
        "  ],\n",
        "  \"rationale\": \"2-3 phrases courtes en fran√ßais justifiant la d√©cision.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1BF9-p9WL-A"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Define the function to extract annotation without strict JSON parsing\n",
        "def extract_annotation_from_raw(raw_response):\n",
        "    \"\"\"Attempts to extract the annotation value from the raw LLM response by searching for 'annotation'.\"\"\"\n",
        "    match = re.search(r'\"annotation\":\\s*\"(.*?)\"', raw_response)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"Extraction Error\"\n",
        "\n",
        "# Initialize a list to store the parsed data\n",
        "parsed_annotations_list = []\n",
        "\n",
        "# Iterate through the llm_annotations list generated in the previous cell\n",
        "for annotation_entry in llm_annotations:\n",
        "    expression = annotation_entry.get('expression', 'N/A')\n",
        "    llm_raw_response = annotation_entry.get('llm_raw_response', '')\n",
        "\n",
        "    # Extract annotation using the new function\n",
        "    annotation = extract_annotation_from_raw(llm_raw_response)\n",
        "\n",
        "\n",
        "    # Append the extracted data to the list\n",
        "    parsed_annotations_list.append({\n",
        "        'expression': expression,\n",
        "        'annotation': annotation,\n",
        "        # We can't reliably extract tests without valid JSON, so we'll set them to N/A for now\n",
        "        'test1_result': \"N/A\",\n",
        "        'test2_result': \"N/A\",\n",
        "        'test3_result': \"N/A\",\n",
        "        'llm_raw_response': llm_raw_response # Keep raw response for debugging\n",
        "    })\n",
        "\n",
        "# Create a pandas DataFrame from the parsed data list\n",
        "df_parsed_annotations = pd.DataFrame(parsed_annotations_list)\n",
        "\n",
        "\n",
        "# Note: We are no longer using the 'llm_raw_response'.apply(lambda x: parse_llm_json(x).get('annotation', 'Parsing Error')) line\n",
        "\n",
        "print(f\"Parsed annotations for {len(df_parsed_annotations)} expressions.\")\n",
        "\n",
        "# Display the first few rows of the parsed DataFrame\n",
        "display(df_parsed_annotations.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qR8YouYTg8f"
      },
      "outputs": [],
      "source": [
        "output_excel_path = \"llm_annotations.xlsx\"\n",
        "df_parsed_annotations.to_excel(output_excel_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42198e18"
      },
      "outputs": [],
      "source": [
        "# Save the formatted annotations to an Excel file\n",
        "output_excel_path = \"llm_annotations.xlsx\"\n",
        "df_parsed_annotations.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"LLM annotations saved to: {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce53ec5e"
      },
      "source": [
        "## Save Results\n",
        "\n",
        "### Subtask:\n",
        "Save the resulting DataFrame to a new Excel file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a6a664f"
      },
      "outputs": [],
      "source": [
        "# Save the formatted annotations to an Excel file\n",
        "output_excel_path = \"llm_annotations.xlsx\"\n",
        "df_llm_annotations.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"LLM annotations saved to: {output_excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3b525ab"
      },
      "source": [
        "# Task\n",
        "Load data from \"polylex_maj.xlsx\" and \"polylexfle.xlsx\", filter rows in \"polylex_maj.xlsx\" where the second column contains \"–Ω–∏—á—å—è\", classify these rows as \"nominal\" or \"verbal\" based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 or 12, merge with \"polylexfle.xlsx\" to get corresponding rows, sort the result by the classification marker (\"verbal\" first), and save the final DataFrame to a new file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6011374b"
      },
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ `polylex_maj.xlsx` –∏ `polylexfle.xlsx` –≤ DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edeb9e2d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to load data from two Excel files into pandas DataFrames as per the instructions. I will use `pd.read_excel` for this purpose and display the head of each DataFrame to confirm successful loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5201d457"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from the first Excel file\n",
        "df_first = pd.read_excel(\"polylex_maj.xlsx\")\n",
        "\n",
        "# Load data from the second Excel file\n",
        "df_second = pd.read_excel(\"polylexfle.xlsx\")\n",
        "\n",
        "# Display the first few rows of each DataFrame to verify loading\n",
        "print(\"First DataFrame (polylex_maj.xlsx):\")\n",
        "display(df_first.head())\n",
        "\n",
        "print(\"\\nSecond DataFrame (polylexfle.xlsx):\")\n",
        "display(df_second.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d42c9fda"
      },
      "source": [
        "## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤ `polylex maj.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ `polylex_maj.xlsx`, –≥–¥–µ –≤–æ –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–µ (–∏–Ω–¥–µ–∫—Å 1) –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Å–ª–æ–≤–æ \"–Ω–∏—á—å—è\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b682ca13"
      },
      "source": [
        "**Reasoning**:\n",
        "Identify the second column and filter the DataFrame based on the presence of \"–Ω–∏—á—å—è\" in that column, then display the head of the filtered DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5656fda"
      },
      "outputs": [],
      "source": [
        "# Identify the second column (index 1)\n",
        "second_column_name = df_first.columns[1]\n",
        "\n",
        "# Filter the DataFrame to keep rows where the second column contains \"–Ω–∏—á—å—è\"\n",
        "df_filtered = df_first[df_first[second_column_name].str.contains(\"–Ω–∏—á—å—è\", na=False)].copy()\n",
        "\n",
        "# Display the first few rows of the filtered DataFrame\n",
        "print(f\"Filtered DataFrame (rows containing '–Ω–∏—á—å—è' in '{second_column_name}'):\")\n",
        "display(df_filtered.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6986fae"
      },
      "source": [
        "## –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–î–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ `polylex_maj.xlsx`, –ø—Ä–∏—Å–≤–æ–∏—Ç—å –º–∞—Ä–∫–µ—Ä \"nominal\" –∏–ª–∏ \"verbal\" –≤ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–∞–ª–∏—á–∏–∏ \"Test_ID_OUI\" –∏–ª–∏ \"Test_ID_NON\" –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö 7 (G) –∏–ª–∏ 12 (L).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18b9255e"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to classify rows based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 or 12 and apply it to the filtered DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c23d6dc"
      },
      "outputs": [],
      "source": [
        "def classify_expression(row):\n",
        "    \"\"\"\n",
        "    Classifies expression as nominal or verbal based on Test_ID presence in columns 7 or 12.\n",
        "    \"\"\"\n",
        "    # Access columns by index (0-based)\n",
        "    col_7_value = row.iloc[6] # 7th column is at index 6\n",
        "    col_12_value = row.iloc[11] # 12th column is at index 11\n",
        "\n",
        "    # Check if values are strings and contain the specified substrings\n",
        "    col_7_is_nominal = isinstance(col_7_value, str) and (\"Test_ID_OUI\" in col_7_value or \"Test_ID_NON\" in col_7_value)\n",
        "    col_12_is_nominal = isinstance(col_12_value, str) and (\"Test_ID_OUI\" in col_12_value or \"Test_ID_NON\" in col_12_value)\n",
        "\n",
        "    if col_7_is_nominal or col_12_is_nominal:\n",
        "        return \"nominal\"\n",
        "    else:\n",
        "        return \"verbal\"\n",
        "\n",
        "# Apply the classification function to create the new column\n",
        "df_filtered['classification_marker'] = df_filtered.apply(classify_expression, axis=1)\n",
        "\n",
        "# Display the first few rows with the new column\n",
        "display(df_filtered[['expression', df_filtered.columns[1], df_filtered.columns[6], df_filtered.columns[11], 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90fc8b13"
      },
      "source": [
        "## –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å `polylexfle.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å `polylexfle.xlsx` –ø–æ –∫–æ–ª–æ–Ω–∫–µ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ `polylexfle.xlsx`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ee3101"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform a left merge of df_filtered with df_second on the expression column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db6386fa"
      },
      "outputs": [],
      "source": [
        "# Identify the column name for the expression in both dataframes. Assuming it is the first column.\n",
        "expression_col_name = df_filtered.columns[0]\n",
        "\n",
        "# Perform a left merge of df_filtered with df_second\n",
        "# This keeps all rows from df_filtered and adds matching columns from df_second\n",
        "df_merged_data = pd.merge(df_filtered, df_second, on=expression_col_name, how='left')\n",
        "\n",
        "# Display the first few rows and the columns of the resulting df_merged_data\n",
        "print(\"Merged DataFrame (df_merged_data):\")\n",
        "display(df_merged_data.head())\n",
        "\n",
        "print(\"\\nColumns in df_merged_data:\")\n",
        "print(df_merged_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a7b7ddd"
      },
      "source": [
        "## –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame —Ç–∞–∫, —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞ —à–ª–∏ —Å—Ç—Ä–æ–∫–∏ —Å –º–∞—Ä–∫–µ—Ä–æ–º \"verbal\", –∞ –∑–∞—Ç–µ–º —Å –º–∞—Ä–∫–µ—Ä–æ–º \"nominal\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5097ce89"
      },
      "source": [
        "**Reasoning**:\n",
        "Sort the merged DataFrame by the 'classification_marker' column, ensuring 'verbal' comes before 'nominal', and then display the head of the sorted DataFrame to verify the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a387b96b"
      },
      "outputs": [],
      "source": [
        "# Define the desired order for sorting\n",
        "sorting_order = ['verbal', 'nominal', 'N/A'] # Including N/A just in case, though not expected based on previous classification\n",
        "\n",
        "# Convert 'classification_marker' to a categorical type with the specified order\n",
        "df_merged_data['classification_marker'] = pd.Categorical(df_merged_data['classification_marker'], categories=sorting_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the categorical column\n",
        "df_merged_data = df_merged_data.sort_values('classification_marker')\n",
        "\n",
        "# Display the first few rows of the sorted DataFrame, including the classification_marker column\n",
        "print(\"Sorted DataFrame (df_merged_data):\")\n",
        "display(df_merged_data[['expression', 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28f725d2"
      },
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ `polylex_maj.xlsx` –∏ `polylexfle.xlsx` –≤ DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49a5db4b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to load data from two Excel files into pandas DataFrames as per the instructions. I will use `pd.read_excel` for this purpose and display the head of each DataFrame to confirm successful loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f1877e7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from the first Excel file\n",
        "df_first = pd.read_excel(\"polylex_maj.xlsx\")\n",
        "\n",
        "# Load data from the second Excel file\n",
        "df_second = pd.read_excel(\"polylexfle.xlsx\")\n",
        "\n",
        "# Display the first few rows of each DataFrame to verify loading\n",
        "print(\"First DataFrame (polylex_maj.xlsx):\")\n",
        "display(df_first.head())\n",
        "\n",
        "print(\"\\nSecond DataFrame (polylexfle.xlsx):\")\n",
        "display(df_second.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7751a5e2"
      },
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "### Subtask:\n",
        "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcb34309"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the final sorted DataFrame to an Excel file without the index and print a confirmation message.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0632f2af"
      },
      "outputs": [],
      "source": [
        "# Select the first column and the last 7 columns\n",
        "# Assuming the first column is 'expression' and it's always the first one after sorting\n",
        "# We need to make sure 'expression' is indeed the first column after sorting,\n",
        "# or select it explicitly by name and then append the last 7 columns.\n",
        "\n",
        "# Get the list of all columns in the sorted DataFrame\n",
        "all_columns = df_merged_data.columns.tolist()\n",
        "\n",
        "# Identify the first column (assuming it's 'expression' based on previous steps and user request)\n",
        "first_column = all_columns[0]\n",
        "\n",
        "# Identify the last 7 columns\n",
        "last_7_columns = all_columns[-7:]\n",
        "\n",
        "# Create a new list of columns to keep: the first column + the last 7 columns\n",
        "# Ensure the first column is not duplicated if it's also one of the last 7\n",
        "columns_to_keep = [first_column] + [col for col in last_7_columns if col != first_column]\n",
        "\n",
        "# Select only the desired columns from the DataFrame\n",
        "df_final_output = df_merged_data[columns_to_keep]\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "output_file_path = \"output_merged_sorted_filtered_columns.xlsx\" # Updated filename to reflect changes\n",
        "df_final_output.to_excel(output_file_path, index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"DataFrame successfully saved to {output_file_path} with selected columns.\")\n",
        "\n",
        "# Display the head of the final output DataFrame\n",
        "print(\"\\nHead of the final saved DataFrame:\")\n",
        "display(df_final_output.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8356b289"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Data was successfully loaded from `polylex_maj.xlsx` and `polylexfle.xlsx` into two separate DataFrames.\n",
        "*   The `polylex_maj.xlsx` DataFrame was filtered to include only rows where the second column ('annotation\\_resolved') contained the substring \"–Ω–∏—á—å—è\".\n",
        "*   A new column, 'classification\\_marker', was added to the filtered DataFrame, classifying rows as \"nominal\" if columns 7 or 12 contained \"Test\\_ID\\_OUI\" or \"Test\\_ID\\_NON\", and \"verbal\" otherwise.\n",
        "*   The filtered and classified DataFrame was successfully merged with the `polylexfle.xlsx` DataFrame using the first column (expression) as the key.\n",
        "*   The merged DataFrame was sorted based on the 'classification\\_marker' column, with \"verbal\" entries preceding \"nominal\" entries.\n",
        "*   The final processed DataFrame was saved to a new Excel file named `output_merged_sorted.xlsx`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The classification logic relies on specific substrings (\"Test\\_ID\\_OUI\", \"Test\\_ID\\_NON\") and column indices; future work could make this more robust by using column names or regular expressions.\n",
        "*   Further analysis could involve examining the distribution of \"nominal\" vs. \"verbal\" classifications among the \"–Ω–∏—á—å—è\" entries or exploring the data from `polylexfle.xlsx` that was merged.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ef64bc1"
      },
      "source": [
        "# Task\n",
        "Load data from \"polylex_maj.xlsx\" and \"polylexfle.xlsx\", filter rows in \"polylex_maj.xlsx\" where the second column contains \"–Ω–∏—á—å—è\", classify these rows as \"nominal\" or \"verbal\" based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns G or L, merge with \"polylexfle.xlsx\" to get corresponding rows, sort the result by the classification marker (\"verbal\" first), keep only the first column ('expression') and the last 7 columns, and save the final DataFrame to a new file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdd95114"
      },
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ `polylex_maj.xlsx` –∏ `polylexfle.xlsx` –≤ DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90f9a6e2"
      },
      "source": [
        "## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤ `polylex maj.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ `polylex_maj.xlsx`, –≥–¥–µ –≤–æ –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–µ (–∏–Ω–¥–µ–∫—Å 1) –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Å–ª–æ–≤–æ \"–Ω–∏—á—å—è\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77978327"
      },
      "source": [
        "## –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–î–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ `polylex_maj.xlsx`, –ø—Ä–∏—Å–≤–æ–∏—Ç—å –º–∞—Ä–∫–µ—Ä \"nominal\" –∏–ª–∏ \"verbal\" –≤ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–∞–ª–∏—á–∏–∏ \"Test_ID_OUI\" –∏–ª–∏ \"Test_ID_NON\" –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö 7 (G) –∏–ª–∏ 12 (L).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126db560"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to classify rows based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 or 12 and apply it to the filtered DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b55b988"
      },
      "outputs": [],
      "source": [
        "def classify_expression(row):\n",
        "    \"\"\"\n",
        "    Classifies expression as nominal or verbal based on Test_ID presence in columns 7 or 12.\n",
        "    \"\"\"\n",
        "    # Access columns by index (0-based)\n",
        "    col_7_value = row.iloc[6] # 7th column is at index 6\n",
        "    col_12_value = row.iloc[11] # 12th column is at index 11\n",
        "\n",
        "    # Check if values are strings and contain the specified substrings\n",
        "    col_7_is_nominal = isinstance(col_7_value, str) and (\"Test_ID_OUI\" in col_7_value or \"Test_ID_NON\" in col_7_value)\n",
        "    col_12_is_nominal = isinstance(col_12_value, str) and (\"Test_ID_OUI\" in col_12_value or \"Test_ID_NON\" in col_12_value)\n",
        "\n",
        "    if col_7_is_nominal or col_12_is_nominal:\n",
        "        return \"nominal\"\n",
        "    else:\n",
        "        return \"verbal\"\n",
        "\n",
        "# Apply the classification function to create the new column\n",
        "df_filtered['classification_marker'] = df_filtered.apply(classify_expression, axis=1)\n",
        "\n",
        "# Display the first few rows with the new column\n",
        "display(df_filtered[['expression', df_filtered.columns[1], df_filtered.columns[6], df_filtered.columns[11], 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "191ee83c"
      },
      "source": [
        "## –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å `polylexfle.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å `polylexfle.xlsx` –ø–æ –∫–æ–ª–æ–Ω–∫–µ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ `polylexfle.xlsx`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dec46015"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform a left merge of df_filtered with df_second on the expression column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "835bf057"
      },
      "outputs": [],
      "source": [
        "# Identify the column name for the expression in both dataframes. Assuming it is the first column.\n",
        "expression_col_name = df_filtered.columns[0]\n",
        "\n",
        "# Perform a left merge of df_filtered with df_second\n",
        "# This keeps all rows from df_filtered and adds matching columns from df_second\n",
        "df_merged_data = pd.merge(df_filtered, df_second, on=expression_col_name, how='left')\n",
        "\n",
        "# Display the first few rows and the columns of the resulting df_merged_data\n",
        "print(\"Merged DataFrame (df_merged_data):\")\n",
        "display(df_merged_data.head())\n",
        "\n",
        "print(\"\\nColumns in df_merged_data:\")\n",
        "print(df_merged_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfd02a29"
      },
      "source": [
        "# Task\n",
        "Load data from \"Fichier initial_11.xlsx\", \"polylex_maj.xlsx\", and \"polylexfle.xlsx\" into DataFrames. Filter rows in `polylex_maj.xlsx` that match expressions in `Fichier initial_11.xlsx`. For the filtered rows, classify them as \"nominal\" or \"verbal\" based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 (G) or 12 (L) and add this classification to a new column. Merge the filtered and classified data with `polylexfle.xlsx` based on the expression column to get corresponding rows from `polylexfle.xlsx`. Sort the merged DataFrame so that rows with the \"verbal\" marker come first, followed by rows with the \"nominal\" marker. Drop all columns except the first ('expression') and the last 7 from the sorted DataFrame. Save the final DataFrame to a new file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a959e17"
      },
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ `Fichier initial_11.xlsx`, `polylex_maj.xlsx` –∏ `polylexfle.xlsx` –≤ DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61af931c"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to load data from three Excel files into pandas DataFrames as per the instructions. I will use `pd.read_excel` for this purpose and display the head of each DataFrame to confirm successful loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3b4d03"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from the first Excel file\n",
        "df_initial_11 = pd.read_excel(\"Fichier initial_11.xlsx\")\n",
        "\n",
        "# Load data from the second Excel file\n",
        "df_first = pd.read_excel(\"polylex_maj.xlsx\")\n",
        "\n",
        "# Load data from the third Excel file\n",
        "df_second = pd.read_excel(\"polylexfle.xlsx\")\n",
        "\n",
        "# Display the first few rows of each DataFrame to verify loading\n",
        "print(\"First DataFrame (Fichier initial_11.xlsx):\")\n",
        "display(df_initial_11.head())\n",
        "\n",
        "print(\"\\nSecond DataFrame (polylex_maj.xlsx):\")\n",
        "display(df_first.head())\n",
        "\n",
        "print(\"\\nThird DataFrame (polylexfle.xlsx):\")\n",
        "display(df_second.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d201ad3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because \"Fichier initial_11.xlsx\" is not a valid zip file, which suggests it might not be a standard Excel file or is corrupted. I will try to read it using a different engine that might handle non-standard Excel files, specifically 'openpyxl', and if that fails, I will try 'xlrd'. If both fail, I will report the failure for this subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6DKO8w46qjS"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Attempt to load with openpyxl\n",
        "    df_initial_11 = pd.read_excel(\"Fichier initial_11.xlsx\", engine='openpyxl')\n",
        "except Exception:\n",
        "    try:\n",
        "        # If openpyxl fails, try with xlrd (for older .xls files)\n",
        "        df_initial_11 = pd.read_excel(\"Fichier initial_11.xlsx\", engine='xlrd')\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load Fichier initial_11.xlsx with both openpyxl and xlrd: {e}\")\n",
        "        df_initial_11 = None # Set to None to indicate failure\n",
        "\n",
        "# Load data from the other two files as they loaded successfully before\n",
        "try:\n",
        "    df_first = pd.read_excel(\"polylex_maj.xlsx\")\n",
        "    df_second = pd.read_excel(\"polylexfle.xlsx\")\n",
        "\n",
        "    # Display the first few rows of each DataFrame if loading was successful\n",
        "    if df_initial_11 is not None:\n",
        "        print(\"First DataFrame (Fichier initial_11.xlsx):\")\n",
        "        display(df_initial_11.head())\n",
        "\n",
        "    print(\"\\nSecond DataFrame (polylex_maj.xlsx):\")\n",
        "    display(df_first.head())\n",
        "\n",
        "    print(\"\\nThird DataFrame (polylexfle.xlsx):\")\n",
        "    display(df_second.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading polylex_maj.xlsx or polylexfle.xlsx: {e}\")\n",
        "    df_first = None\n",
        "    df_second = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0e4b1cb"
      },
      "source": [
        "## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ `fichier initial 11.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ `polylex_maj.xlsx`, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –∏–∑ `Fichier initial_11.xlsx`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44952dcd"
      },
      "source": [
        "## –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–î–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ `polylex_maj.xlsx`, –ø—Ä–∏—Å–≤–æ–∏—Ç—å –º–∞—Ä–∫–µ—Ä \"nominal\" –∏–ª–∏ \"verbal\" –≤ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–∞–ª–∏—á–∏–∏ \"Test_ID_OUI\" –∏–ª–∏ \"Test_ID_NON\" –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö 7 (G) –∏–ª–∏ 12 (L).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "628a9210"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to classify rows based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 or 12 and apply it to the filtered DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2cd2453"
      },
      "outputs": [],
      "source": [
        "def classify_expression(row):\n",
        "    \"\"\"\n",
        "    Classifies expression as nominal or verbal based on Test_ID presence in columns 7 or 12.\n",
        "    \"\"\"\n",
        "    # Access columns by index (0-based)\n",
        "    col_7_value = row.iloc[6] # 7th column is at index 6\n",
        "    col_12_value = row.iloc[11] # 12th column is at index 11\n",
        "\n",
        "    # Check if values are strings and contain the specified substrings\n",
        "    col_7_is_nominal = isinstance(col_7_value, str) and (\"Test_ID_OUI\" in col_7_value or \"Test_ID_NON\" in col_7_value)\n",
        "    col_12_is_nominal = isinstance(col_12_value, str) and (\"Test_ID_OUI\" in col_12_value or \"Test_ID_NON\" in col_12_value)\n",
        "\n",
        "    if col_7_is_nominal or col_12_is_nominal:\n",
        "        return \"nominal\"\n",
        "    else:\n",
        "        return \"verbal\"\n",
        "\n",
        "# Apply the classification function to create the new column\n",
        "df_filtered['classification_marker'] = df_filtered.apply(classify_expression, axis=1)\n",
        "\n",
        "# Display the first few rows with the new column\n",
        "display(df_filtered[['expression', df_filtered.columns[1], df_filtered.columns[6], df_filtered.columns[11], 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "144a4bc3"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform a left merge of df_filtered with df_second on the expression column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de59c543"
      },
      "outputs": [],
      "source": [
        "# Identify the column name for the expression in both dataframes. Assuming it is the first column.\n",
        "expression_col_name = df_filtered.columns[0]\n",
        "\n",
        "# Perform a left merge of df_filtered with df_second\n",
        "# This keeps all rows from df_filtered and adds matching columns from df_second\n",
        "df_merged_data = pd.merge(df_filtered, df_second, on=expression_col_name, how='left')\n",
        "\n",
        "# Display the first few rows and the columns of the resulting df_merged_data\n",
        "print(\"Merged DataFrame (df_merged_data):\")\n",
        "display(df_merged_data.head())\n",
        "\n",
        "print(\"\\nColumns in df_merged_data:\")\n",
        "print(df_merged_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eaa60d9"
      },
      "source": [
        "**Reasoning**:\n",
        "Sort the merged DataFrame by the 'classification_marker' column, ensuring 'verbal' comes before 'nominal', and then display the head of the sorted DataFrame to verify the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2554805a"
      },
      "outputs": [],
      "source": [
        "# Define the desired order for sorting\n",
        "sorting_order = ['verbal', 'nominal', 'N/A'] # Including N/A just in case, though not expected based on previous classification\n",
        "\n",
        "# Convert 'classification_marker' to a categorical type with the specified order\n",
        "df_merged_data['classification_marker'] = pd.Categorical(df_merged_data['classification_marker'], categories=sorting_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the categorical column\n",
        "df_merged_data = df_merged_data.sort_values('classification_marker')\n",
        "\n",
        "# Display the first few rows of the sorted DataFrame, including the classification_marker column\n",
        "print(\"Sorted DataFrame (df_merged_data):\")\n",
        "display(df_merged_data[['expression', 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122f4e69"
      },
      "source": [
        "**Reasoning**:\n",
        "Select the first column and the last 7 columns from the sorted DataFrame and save the result to an Excel file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f78fff5"
      },
      "outputs": [],
      "source": [
        "# Get the list of all columns in the sorted DataFrame\n",
        "all_columns = df_merged_data.columns.tolist()\n",
        "\n",
        "# Identify the first column (assuming it's 'expression' based on previous steps and user request)\n",
        "first_column = all_columns[0]\n",
        "\n",
        "# Identify the last 7 columns\n",
        "last_7_columns = all_columns[-7:]\n",
        "\n",
        "# Create a new list of columns to keep: the first column + the last 7 columns\n",
        "# Ensure the first column is not duplicated if it's also one of the last 7\n",
        "columns_to_keep = [first_column] + [col for col in last_7_columns if col != first_column]\n",
        "\n",
        "# Select only the desired columns from the DataFrame\n",
        "df_final_output = df_merged_data[columns_to_keep]\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "output_file_path = \"output_merged_sorted_filtered_columns.xlsx\" # Updated filename to reflect changes\n",
        "df_final_output.to_excel(output_file_path, index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"DataFrame successfully saved to {output_file_path} with selected columns.\")\n",
        "\n",
        "# Display the head of the final output DataFrame\n",
        "print(\"\\nHead of the final saved DataFrame:\")\n",
        "display(df_final_output.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e9d9454"
      },
      "source": [
        "## –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫\n",
        "\n",
        "### Subtask:\n",
        "–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π ('expression') –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 7, –∏–∑ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d79eae9"
      },
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "### Subtask:\n",
        "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π DataFrame –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eca52ad"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the final dataframe to an Excel file and confirm the save location.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d37cd817"
      },
      "outputs": [],
      "source": [
        "# Save the final DataFrame to a new Excel file\n",
        "output_file_path = \"final_output.xlsx\"\n",
        "df_final_output.to_excel(output_file_path, index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"DataFrame successfully saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "579b45e0"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial attempt to load `Fichier initial_11.xlsx` failed due to a `BadZipFile` error, indicating a potential issue with the file format or corruption.\n",
        "*   `polylex_maj.xlsx` and `polylexfle.xlsx` were successfully loaded into `df_first` and `df_second` respectively.\n",
        "*   Rows in `df_filtered` (derived from `df_first`) were successfully classified as \"nominal\" or \"verbal\" based on specific criteria in columns 7 and 12, and this classification was added to a new column named 'classification\\_marker'.\n",
        "*   `df_filtered` was successfully merged with `df_second` based on the 'expression' column, creating `df_merged_data`.\n",
        "*   `df_merged_data` was successfully sorted to prioritize rows with the \"verbal\" classification marker.\n",
        "*   The final DataFrame `df_final_output` was created by selecting the first column ('expression') and the last 7 columns from the sorted `df_merged_data`.\n",
        "*   The final processed DataFrame was successfully saved to an Excel file named \"final\\_output.xlsx\".\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Investigate the `Fichier initial_11.xlsx` file to understand and resolve the `BadZipFile` error to potentially include its data in future analyses.\n",
        "*   Review the criteria for \"nominal\" and \"verbal\" classification to ensure they accurately reflect the desired categories and consider potential edge cases or alternative classification methods if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e58e4cb5"
      },
      "source": [
        "# Task\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ \"Fichier initial_11.xlsx\", \"polylex_maj.xlsx\" –∏ \"polylexfle.xlsx\", –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–π—Ç–µ —Å—Ç—Ä–æ–∫–∏ –≤ \"polylex_maj.xlsx\" –ø–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –∏–∑ \"Fichier initial_11.xlsx\", –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ \"nominal\" –∏–ª–∏ \"verbal\" –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö G –∏ L, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ —Å \"polylexfle.xlsx\" –ø–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—é, –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –ø–æ –º–∞—Ä–∫–µ—Ä—É (\"verbal\" –∑–∞—Ç–µ–º \"nominal\"), –æ—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –∫–æ–ª–æ–Ω–æ–∫, –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5326bbf"
      },
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ `Fichier initial_11.xlsx`, `polylex_maj.xlsx` –∏ `polylexfle.xlsx` –≤ DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ebd9816"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to load data from three Excel files into pandas DataFrames as per the instructions. I will try to load \"Fichier initial_11.xlsx\" with 'openpyxl' and then 'xlrd' if the first fails. I will then load the other two files and display the head of each DataFrame to confirm successful loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53775df0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from the first Excel file with fallback engines\n",
        "try:\n",
        "    df_initial_11 = pd.read_excel(\"Fichier initial_11.xlsx\", engine='openpyxl')\n",
        "except Exception:\n",
        "    try:\n",
        "        # If openpyxl fails, try with xlrd (for older .xls files)\n",
        "        df_initial_11 = pd.read_excel(\"Fichier initial_11.xlsx\", engine='xlrd')\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load Fichier initial_11.xlsx with both openpyxl and xlrd: {e}\")\n",
        "        df_initial_11 = None # Set to None to indicate failure\n",
        "\n",
        "# Load data from the other two files\n",
        "try:\n",
        "    df_first = pd.read_excel(\"polylex_maj.xlsx\")\n",
        "    df_second = pd.read_excel(\"polylexfle.xlsx\")\n",
        "\n",
        "    # Display the first few rows of each DataFrame if loading was successful\n",
        "    if df_initial_11 is not None:\n",
        "        print(\"First DataFrame (Fichier initial_11.xlsx):\")\n",
        "        display(df_initial_11.head())\n",
        "\n",
        "    print(\"\\nSecond DataFrame (polylex_maj.xlsx):\")\n",
        "    display(df_first.head())\n",
        "\n",
        "    print(\"\\nThird DataFrame (polylexfle.xlsx):\")\n",
        "    display(df_second.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading polylex_maj.xlsx or polylexfle.xlsx: {e}\")\n",
        "    df_first = None\n",
        "    df_second = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c0e9ea5"
      },
      "source": [
        "## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ `fichier initial 11.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ `polylex_maj.xlsx`, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –∏–∑ `Fichier initial_11.xlsx`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46e42365"
      },
      "source": [
        "**Reasoning**:\n",
        "Check if the necessary dataframes were loaded, identify the expression column, filter the first dataframe based on expressions in the initial dataframe, and display the head and shape of the filtered dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1618541"
      },
      "outputs": [],
      "source": [
        "# Check if dataframes were loaded successfully\n",
        "if df_first is None or df_initial_11 is None:\n",
        "    print(\"Error: Necessary dataframes were not loaded in the previous step.\")\n",
        "else:\n",
        "    # Identify the expression column (assuming it's the first column)\n",
        "    expression_col_name_first = df_first.columns[0]\n",
        "    expression_col_name_initial = df_initial_11.columns[0]\n",
        "\n",
        "    # Create a set of unique expressions from df_initial_11\n",
        "    initial_expressions = set(df_initial_11[expression_col_name_initial].dropna())\n",
        "\n",
        "    # Filter df_first to keep rows where the expression is in the initial_expressions set\n",
        "    df_filtered = df_first[df_first[expression_col_name_first].isin(initial_expressions)].copy()\n",
        "\n",
        "    # Display the first few rows of the filtered DataFrame\n",
        "    print(\"Filtered DataFrame (df_filtered):\")\n",
        "    display(df_filtered.head())\n",
        "\n",
        "    # Print the shape of the filtered DataFrame\n",
        "    print(\"\\nShape of the filtered DataFrame:\")\n",
        "    print(df_filtered.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ce46a09"
      },
      "source": [
        "## –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### Subtask:\n",
        "–î–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ `polylex_maj.xlsx`, –ø—Ä–∏—Å–≤–æ–∏—Ç—å –º–∞—Ä–∫–µ—Ä \"nominal\" –∏–ª–∏ \"verbal\" –≤ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–∞–ª–∏—á–∏–∏ \"Test_ID_OUI\" –∏–ª–∏ \"Test_ID_NON\" –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö 7 (G) –∏–ª–∏ 12 (L).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cd87e4a"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to classify rows based on the presence of \"Test_ID_OUI\" or \"Test_ID_NON\" in columns 7 or 12 and apply it to the filtered DataFrame, then display the head of the DataFrame with the new column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "554c2463"
      },
      "outputs": [],
      "source": [
        "def classify_expression(row):\n",
        "    \"\"\"\n",
        "    Classifies expression as nominal or verbal based on Test_ID presence in columns 7 or 12.\n",
        "    \"\"\"\n",
        "    # Access columns by index (0-based)\n",
        "    col_7_value = row.iloc[6] # 7th column is at index 6\n",
        "    col_12_value = row.iloc[11] # 12th column is at index 11\n",
        "\n",
        "    # Check if values are strings and contain the specified substrings\n",
        "    col_7_is_nominal = isinstance(col_7_value, str) and (\"Test_ID_OUI\" in col_7_value or \"Test_ID_NON\" in col_7_value)\n",
        "    col_12_is_nominal = isinstance(col_12_value, str) and (\"Test_ID_OUI\" in col_12_value or \"Test_ID_NON\" in col_12_value)\n",
        "\n",
        "    if col_7_is_nominal or col_12_is_nominal:\n",
        "        return \"nominal\"\n",
        "    else:\n",
        "        return \"verbal\"\n",
        "\n",
        "# Apply the classification function to create the new column\n",
        "df_filtered['classification_marker'] = df_filtered.apply(classify_expression, axis=1)\n",
        "\n",
        "# Display the first few rows with the new column\n",
        "display(df_filtered[['expression', df_filtered.columns[1], df_filtered.columns[6], df_filtered.columns[11], 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7c8a984"
      },
      "source": [
        "## –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å `polylexfle.xlsx`\n",
        "\n",
        "### Subtask:\n",
        "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å `polylexfle.xlsx` –ø–æ –∫–æ–ª–æ–Ω–∫–µ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ `polylexfle.xlsx`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5995ff8"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform a left merge of df_filtered with df_second on the expression column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e69d09a1"
      },
      "outputs": [],
      "source": [
        "# Identify the column name for the expression in both dataframes. Assuming it is the first column.\n",
        "expression_col_name = df_filtered.columns[0]\n",
        "\n",
        "# Perform a left merge of df_filtered with df_second\n",
        "# This keeps all rows from df_filtered and adds matching columns from df_second\n",
        "df_merged_data = pd.merge(df_filtered, df_second, on=expression_col_name, how='left')\n",
        "\n",
        "# Display the first few rows and the columns of the resulting df_merged_data\n",
        "print(\"Merged DataFrame (df_merged_data):\")\n",
        "display(df_merged_data.head())\n",
        "\n",
        "print(\"\\nColumns in df_merged_data:\")\n",
        "print(df_merged_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f80a083"
      },
      "source": [
        "## –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞\n",
        "\n",
        "### Subtask:\n",
        "–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame —Ç–∞–∫, —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞ —à–ª–∏ —Å—Ç—Ä–æ–∫–∏ —Å –º–∞—Ä–∫–µ—Ä–æ–º \"verbal\", –∞ –∑–∞—Ç–µ–º —Å –º–∞—Ä–∫–µ—Ä–æ–º \"nominal\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc43b2ef"
      },
      "source": [
        "**Reasoning**:\n",
        "Sort the merged DataFrame by the 'classification_marker' column, ensuring 'verbal' comes before 'nominal', and then display the head of the sorted DataFrame to verify the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15680f1"
      },
      "outputs": [],
      "source": [
        "# Define the desired order for sorting\n",
        "sorting_order = ['verbal', 'nominal', 'N/A'] # Including N/A just in case, though not expected based on previous classification\n",
        "\n",
        "# Convert 'classification_marker' to a categorical type with the specified order\n",
        "df_merged_data['classification_marker'] = pd.Categorical(df_merged_data['classification_marker'], categories=sorting_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the categorical column\n",
        "df_merged_data = df_merged_data.sort_values('classification_marker')\n",
        "\n",
        "# Display the first few rows of the sorted DataFrame, including the classification_marker column\n",
        "print(\"Sorted DataFrame (df_merged_data):\")\n",
        "display(df_merged_data[['expression', 'classification_marker']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c95bc3d5"
      },
      "source": [
        "## –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫\n",
        "\n",
        "### Subtask:\n",
        "–í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e14c8345"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the list of all column names, identify the first and last 7 columns, create a list of columns to keep, select these columns to create the final DataFrame, and display the head of the final DataFrame for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5356877f"
      },
      "outputs": [],
      "source": [
        "# Get the list of all columns in the sorted DataFrame\n",
        "all_columns = df_merged_data.columns.tolist()\n",
        "\n",
        "# Identify the first column (assuming it's 'expression' based on previous steps and user request)\n",
        "first_column = all_columns[0]\n",
        "\n",
        "# Identify the last 7 columns\n",
        "last_7_columns = all_columns[-7:]\n",
        "\n",
        "# Create a new list of columns to keep: the first column + the last 7 columns\n",
        "# Ensure the first column is not duplicated if it's also one of the last 7\n",
        "columns_to_keep = [first_column] + [col for col in last_7_columns if col != first_column]\n",
        "\n",
        "# Select only the desired columns from the DataFrame\n",
        "df_final_output = df_merged_data[columns_to_keep].copy()\n",
        "\n",
        "# Display the first few rows of the final output DataFrame\n",
        "print(\"\\nHead of the final saved DataFrame:\")\n",
        "display(df_final_output.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcfa652b"
      },
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "### Subtask:\n",
        "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π DataFrame –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3412d2"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the final dataframe to an Excel file and confirm the save location.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74dbfa9d"
      },
      "outputs": [],
      "source": [
        "# Save the final DataFrame to a new Excel file\n",
        "output_file_path = \"final_output.xlsx\"\n",
        "df_final_output.to_excel(output_file_path, index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"DataFrame successfully saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd430af2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Data was successfully loaded from three Excel files: \"Fichier initial\\_11.xlsx\", \"polylex\\_maj.xlsx\", and \"polylexfle.xlsx\".\n",
        "*   The `polylex_maj.xlsx` data was filtered to include only rows where the first column's expression matched expressions found in the first column of \"Fichier initial\\_11.xlsx\". This resulted in 409 filtered rows.\n",
        "*   A new column, 'classification\\_marker', was added to the filtered data, classifying rows as \"nominal\" or \"verbal\" based on the presence of \"Test\\_ID\\_OUI\" or \"Test\\_ID\\_NON\" in the 7th or 12th columns.\n",
        "*   The filtered and classified data was successfully merged with the `polylexfle.xlsx` data based on the expression column.\n",
        "*   The merged data was sorted to prioritize rows with the \"verbal\" classification marker, followed by \"nominal\".\n",
        "*   The final output DataFrame was created containing only the first column (assumed to be 'expression') and the last 7 columns of the sorted, merged data.\n",
        "*   The final processed data was saved to a new Excel file named \"final\\_output.xlsx\".\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The classification logic relies on the specific strings \"Test\\_ID\\_OUI\" and \"Test\\_ID\\_NON\" and their presence in columns G and L. Any variations or alternative indicators would require updating the classification function.\n",
        "*   The task assumes the first column across all input files is the expression column used for filtering and merging. Verifying this assumption or making the column identification more robust could improve the process's reliability.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}