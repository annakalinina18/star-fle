{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOua+84IQp96NGyLZDwYqJR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import stanza\n","from tqdm import tqdm\n","\n","INPUT_XLSX = \"polylex_maj_16.01.-1.xlsx\"\n","OUTPUT_XLSX = \"polylex_with_ud_stanza.xlsx\"\n","TEXT_COL = \"expression\"   # поменяй, если нужно\n","\n","# ====== INIT STANZA ======\n","# Один раз:\n","# stanza.download(\"fr\", processors=\"tokenize,pos,lemma,depparse\")\n","\n","nlp = stanza.Pipeline(\n","    lang=\"fr\",\n","    processors=\"tokenize,pos,lemma,depparse\",\n","    tokenize_no_ssplit=True,\n","    verbose=False\n",")\n","\n","def normalize_dep_pattern(sent):\n","    words = sent.words\n","    root = next((w for w in words if w.deprel == \"root\"), None)\n","\n","    arcs = []\n","    case_preps = []\n","    for w in words:\n","        if w.deprel == \"root\":\n","            continue\n","        head = words[w.head - 1] if w.head > 0 else None\n","        if not head:\n","            continue\n","        arcs.append(f\"{w.deprel}({head.upos}->{w.upos})\")\n","        if w.deprel == \"case\" and w.text:\n","            case_preps.append(w.text.lower())\n","\n","    arcs_sorted = \" ; \".join(sorted(arcs))\n","    prep_info = \"\"\n","    if case_preps:\n","        prep_info = f\" | case_preps={','.join(sorted(set(case_preps)))}\"\n","\n","    head_info = f\"HEAD={root.upos}\" if root else \"HEAD=?\"\n","    return head_info + \" | \" + arcs_sorted + prep_info\n","\n","def annotate_one(text):\n","    text = str(text).strip()\n","    if not text:\n","        return {\n","            \"ud_tokens\": \"\",\n","            \"ud_lemmas\": \"\",\n","            \"ud_upos\": \"\",\n","            \"ud_xpos\": \"\",\n","            \"ud_feats\": \"\",\n","            \"ud_deprel\": \"\",\n","            \"ud_heads\": \"\",\n","            \"ud_dep_arcs\": \"\",\n","            \"ud_pos_pattern\": \"\",\n","            \"ud_dep_pattern\": \"\"\n","        }\n","\n","    doc = nlp(text)\n","    sent = doc.sentences[0]\n","\n","    return {\n","        \"ud_tokens\": \" \".join(w.text for w in sent.words),\n","        \"ud_lemmas\": \" \".join(w.lemma or \"\" for w in sent.words),\n","        \"ud_upos\": \" \".join(w.upos for w in sent.words),\n","        \"ud_xpos\": \" \".join(w.xpos or \"\" for w in sent.words),\n","        \"ud_feats\": \" | \".join(w.feats or \"\" for w in sent.words),\n","        \"ud_deprel\": \" \".join(w.deprel for w in sent.words),\n","        \"ud_heads\": \" \".join(str(w.head) for w in sent.words),\n","        \"ud_dep_arcs\": \" ; \".join(\n","            f\"{w.text}<-{w.deprel}-({sent.words[w.head-1].text if w.head>0 else 'ROOT'})\"\n","            for w in sent.words\n","        ),\n","        \"ud_pos_pattern\": \" \".join(w.upos for w in sent.words),\n","        \"ud_dep_pattern\": normalize_dep_pattern(sent),\n","    }\n","\n","# ====== RUN ======\n","df = pd.read_excel(INPUT_XLSX)\n","\n","results = []\n","for text in tqdm(df[TEXT_COL], desc=\"Annotating expressions\", unit=\"expr\"):\n","    results.append(annotate_one(text))\n","\n","ann_df = pd.DataFrame(results)\n","out = pd.concat([df, ann_df], axis=1)\n","out.to_excel(OUTPUT_XLSX, index=False)\n","\n","print(\"Saved:\", OUTPUT_XLSX)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8U6v8MLr5FWS","executionInfo":{"status":"ok","timestamp":1768568750320,"user_tz":-180,"elapsed":335051,"user":{"displayName":"Anna Kalinina","userId":"16156166223513079181"}},"outputId":"26677576-483d-4d3a-c57c-a42feb87591f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Annotating expressions: 100%|██████████| 2268/2268 [05:26<00:00,  6.95expr/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved: polylex_with_ud_stanza.xlsx\n"]}]}]}
