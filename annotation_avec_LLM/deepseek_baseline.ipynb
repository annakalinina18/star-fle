{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annakalinina18/star-fle/blob/main/annotation_avec_LLM/deepseek_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "# =========================\n",
        "# 0. CLIENT (DeepSeek via API)\n",
        "# =========================\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"\",\n",
        "    base_url=\"https://api.deepseek.com\"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 1. МОДЕЛЬ\n",
        "# =========================\n",
        "MODEL_NAME = \"deepseek-chat\"\n",
        "# MODEL_NAME = \"deepseek-reasoner\"\n",
        "\n",
        "# =========================\n",
        "# 2. BASELINE PROMPT (définitions générales, pas de guide)\n",
        "# =========================\n",
        "BASELINE_PROMPT = \"\"\"\n",
        "Tu es linguiste.\n",
        "\n",
        "Ta tâche est de classer une expression nominale française\n",
        "dans UNE SEULE des catégories suivantes, en te fondant sur\n",
        "une compréhension linguistique générale (pas de guide spécifique).\n",
        "\n",
        "Catégories :\n",
        "\n",
        "1) Expression_idiomatique\n",
        "Expression figée dont le sens global n’est pas directement déductible\n",
        "du sens littéral de ses mots.\n",
        "Exemples : « lune de miel », « forêt noire » (gâteau)\n",
        "\n",
        "2) Collocation_opaque\n",
        "Association de mots relativement conventionnelle,\n",
        "dont le sens implique une image, une métaphore ou une métonymie.\n",
        "Exemples : « fil rouge », « train de vie »\n",
        "\n",
        "3) Collocation_transparente\n",
        "Association de mots fréquente ou conventionnelle,\n",
        "dont le sens est globalement déductible des mots qui la composent.\n",
        "Exemples : « événement culturel », « roman policier »\n",
        "\n",
        "4) Expression_libre\n",
        "Combinaison de mots construite librement en discours,\n",
        "sans caractère figé ou conventionnel particulier.\n",
        "Exemples : « livre intéressant », « maison ancienne »\n",
        "\n",
        "Contraintes :\n",
        "- Choisis UNE seule catégorie.\n",
        "- Réponds uniquement selon le format ci-dessous.\n",
        "\n",
        "FORMAT OBLIGATOIRE :\n",
        "Catégorie : <Expression_idiomatique | Collocation_opaque | Collocation_transparente | Expression_libre>\n",
        "Explication : <une phrase très courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "ALLOWED = {\n",
        "    \"Expression_idiomatique\",\n",
        "    \"Collocation_opaque\",\n",
        "    \"Collocation_transparente\",\n",
        "    \"Expression_libre\",\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 3. APPEL LLM (baseline)\n",
        "# =========================\n",
        "def classify_expression_baseline(expression, examples):\n",
        "    contexte = \"\" if examples is None or pd.isna(examples) else str(examples)\n",
        "\n",
        "    prompt = BASELINE_PROMPT.format(\n",
        "        expression=str(expression).strip(),\n",
        "        contexte=contexte\n",
        "    )\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        max_tokens=80,\n",
        "    )\n",
        "\n",
        "    text = (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "    # validation minimale du format/catégorie\n",
        "    cat = None\n",
        "    for line in text.splitlines():\n",
        "        if line.lower().startswith(\"catégorie\"):\n",
        "            cat = line.split(\":\", 1)[-1].strip()\n",
        "            break\n",
        "\n",
        "    if cat not in ALLOWED:\n",
        "        text = (\n",
        "            \"Catégorie : INVALID\\n\"\n",
        "            \"Explication : Réponse hors format.\\n\\n\"\n",
        "            + text\n",
        "        )\n",
        "\n",
        "    return text\n",
        "\n",
        "# =========================\n",
        "# 4. TRAITEMENT EXCEL\n",
        "# =========================\n",
        "input_file = \"nominal_part_7.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "df[\"llm_raw_response\"] = None\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Baseline annotation\"):\n",
        "    expr = row.get(\"expression\")\n",
        "    ex = row.get(\"examples_joined\")\n",
        "\n",
        "    if pd.isna(expr) or not str(expr).strip():\n",
        "        df.at[idx, \"llm_raw_response\"] = \"N/A\"\n",
        "        continue\n",
        "\n",
        "    df.at[idx, \"llm_raw_response\"] = classify_expression_baseline(expr, ex)\n",
        "\n",
        "output_file = \"annotated_nominal_part_7_deepseek_baseline_general_defs.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Saved: {output_file}\")\n"
      ],
      "metadata": {
        "id": "oUN2nb6p0gzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b735e2c6-bc70-4671-c6ad-ec2872783a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Baseline annotation: 100%|██████████| 100/100 [04:05<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: annotated_nominal_part_7_deepseek_baseline_general_defs.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}