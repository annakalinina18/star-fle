{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOlO6rTz96sD176Ts9EVne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annakalinina18/star-fle/blob/main/annotation_avec_LLM/mistral_large_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9HEYJukmGiJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "# =========================\n",
        "# 0. CLIENT\n",
        "# =========================\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"\",\n",
        "    base_url=\"https://api.mistral.ai/v1\"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 1. MODÈLE\n",
        "# =========================\n",
        "\n",
        "MODEL_NAME = \"mistral-large\"\n",
        "\n",
        "# =========================\n",
        "# 2. BASELINE PROMPT (segmentation)\n",
        "# =========================\n",
        "\n",
        "BASELINE_PROMPT = \"\"\"\n",
        "Tu es linguiste.\n",
        "\n",
        "Ta tâche est de décider si l’expression fournie\n",
        "constitue une expression polylexicale figée\n",
        "ou une combinaison libre.\n",
        "\n",
        "Définitions :\n",
        "\n",
        "Expression_polylexicale :\n",
        "Suite de mots formant une unité relativement figée,\n",
        "conventionnelle ou lexicalisée.\n",
        "\n",
        "Combinaison_libre :\n",
        "Suite de mots construite librement en discours,\n",
        "sans figement particulier.\n",
        "\n",
        "Réponds UNIQUEMENT selon le format :\n",
        "\n",
        "Décision : <Expression_polylexicale | Combinaison_libre>\n",
        "Explication : <une phrase courte>\n",
        "\n",
        "Expression : {expression}\n",
        "Contexte : {contexte}\n",
        "\"\"\"\n",
        "\n",
        "ALLOWED = {\n",
        "    \"Expression_polylexicale\",\n",
        "    \"Combinaison_libre\",\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 3. APPEL LLM\n",
        "# =========================\n",
        "\n",
        "def classify_baseline(expression, examples):\n",
        "    contexte = \"\" if examples is None or pd.isna(examples) else str(examples)\n",
        "\n",
        "    prompt = BASELINE_PROMPT.format(\n",
        "        expression=str(expression).strip(),\n",
        "        contexte=contexte\n",
        "    )\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        max_tokens=80,\n",
        "    )\n",
        "\n",
        "    text = (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "    decision = None\n",
        "    for line in text.splitlines():\n",
        "        if line.lower().startswith(\"décision\"):\n",
        "            decision = line.split(\":\", 1)[-1].strip()\n",
        "            break\n",
        "\n",
        "    if decision not in ALLOWED:\n",
        "        text = (\n",
        "            \"Décision : INVALID\\n\"\n",
        "            \"Explication : Réponse hors format.\\n\\n\"\n",
        "            + text\n",
        "        )\n",
        "\n",
        "    return text\n",
        "\n",
        "# =========================\n",
        "# 4. TRAITEMENT EXCEL\n",
        "# =========================\n",
        "\n",
        "input_file = \"segmentation_input.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "df[\"llm_raw_response\"] = None\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Baseline segmentation\"):\n",
        "    expr = row.get(\"expression\")\n",
        "    ex = row.get(\"examples_joined\")\n",
        "\n",
        "    if pd.isna(expr) or not str(expr).strip():\n",
        "        df.at[idx, \"llm_raw_response\"] = \"N/A\"\n",
        "        continue\n",
        "\n",
        "    df.at[idx, \"llm_raw_response\"] = classify_baseline(expr, ex)\n",
        "\n",
        "output_file = \"annotated_segmentation_baseline_mistral.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Saved: {output_file}\")\n"
      ]
    }
  ]
}